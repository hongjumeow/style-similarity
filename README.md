# Calculating Style Similarity between datasets

Comparing Styles between datasets, inspired by [Neural Algorithm for Artistic Style](https://arxiv.org/abs/1508.06576) (Gatys et al.), implemented by [hongjumeow](https://github.com/hongjumeow).


### Algorithm

As mentioned in [Neural Algorithm for Artistic Style](https://arxiv.org/abs/1508.06576), I used distance between Style Representations of datasets, from feature maps generated by CNN, which here, is in form of VGGNet.

Using Gram Matrix, got distance between style representations.

```Python
feat1_shaped = feat1.view(channel, height * width)
feat2_shaped = feat2.view(channel, height * width)

G = torch.mm(feat1_shaped, feat1_shaped.t())
A = torch.mm(feat2_shaped, feat2_shaped.t())

distance = torch.mean((G-A) ** 2)
```

### How to Run Code

``` 
$ python compare.py --dataset1 [path_to_dataset1] --dataset2 [path_to_dataset2] --num_images (optional)[images_amount_to_compare]
```

